---
title: "Clean/Filter Data"
description: "A tutorial about how to clean or filter raw tracking data using the MoveR package."
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    fig_caption: true
    number_sections: false
    global_numbering: false
    link-citations: yes
pkgdown:
  as_is: true
---


<a href="https://qpetitjean.github.io/MoveR/articles/MoveR-ImportData.html" class="previous">&laquo; Previous</a><a href="https://qpetitjean.github.io/MoveR/articles/MoveR-ComputeMetrics.html" class="next">Next &raquo;</a><br />


Now that we are familiar with importing raw data from tracking software, we are focusing on how to clean/filter them.

For this example we are selecting the second sample of data available in the <a href="https://github.com/qpetitjean/MoveR_SampleData">MoveR_SampleData</a> github repository. 

Briefly, this dataset comes from the video recording (image resolution: 1920x1080) of 24 parasitic micro-wasp individuals (genus <i>Trichogramma</i>) placed in a thermostated circular arena (2.5cm diameter, see Ion Scotta et al., 2021) for 110 minutes at 25 fps (see fig. \@ref(fig:VideoPics) left panel). 

Over the exposure duration individuals has been exposed to a steady increases in temperature from 18&#8451; to 45&#8451; followed by a steady decreases from 45&#8451; to 18&#8451; (temperature changing rate: 0.5&#8451; per minutes). Individuals were then tracked using <a href="https://trex.run">TRex</a> (Walter and Couzin, 2021). 

To reduce space allocation and computing time we reduced the dataset by removing the movements recorded below 35&#8451; (see fig. \@ref(fig:VideoPics) right panel). 

```{r VideoPics, echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width="49%", fig.show='hold', fig.cap=" Frames extracted from a video recording of 24 parasitic micro-wasps (genus <em>Trichogramma</em>) placed in a thermostated circular arena (left). Temperature ramp over which the movements of parasitic micro-wasp were recorded. The shaded area corresponds to the part of the data removed from the original dataset (i.e., moments where temperature was below 35&#8451;) while the white area correspond to the remaining data used in the following exemple (right)."}
knitr::include_graphics(
  c('https://github.com/qpetitjean/MoveR_SampleData/raw/main/sample_2/2021-03-01-ISA17150-chaud.gif',
    'https://github.com/qpetitjean/MoveR_SampleData/raw/main/sample_2/Sample2_ReducedData.png')
  )
## Make GIF
```

## Import sample data from github

Let's download the data, import and convert them to a list of tracklets (see the <a href="https://qpetitjean.github.io/MoveR/articles/MoveR-ImportData.html">Import Data vignette</a> for detailed procedure).

<p class="notes">
Note that we have included some extra data that are related to this dataset within the "raw tracking data" when we have reduced the dataset: 

  * the timeline expressed in frame (may be different from the default frame list because the data come from merged videos)

  * the temperature at which the individuals are exposed over the assay 

These extra information will be useful to conduct further analyses in this tutorial and some others.
For instance, we can automatically determine the frame rate of the video-recording using the timeline and timestamps (usually made using the default frame list instead of timeline).</p>

```{r DLsampleData, echo=TRUE}
# dl the second dataset from the sample data repository
Path2Data <- MoveR::DLsampleData(dataSet = 2, tracker = "TRex")

# Import the sample data
TRexDat <- MoveR::readTrex(Path2Data[[1]],
                           rawDat = T)

# retrieve some data specifically related to the dataset (the timeline and related temperature stored in the Data_Trex_Raw sublist)
TRexDat <- c(TRexDat[[1]], 
             TRexDat[[2]]["runTimelinef"],
             TRexDat[[2]]["Measured_Temp_Deg_C"])

# retrieve the frame rate of the video (fps)
frameRate <- max(TRexDat[["runTimelinef"]], na.rm=T) / max(TRexDat[["timestamps"]], na.rm=T)

# convert the data to a list of tracklets
# NB: remove ntargets and timestamps because their length is lower than other variables
trackDat <- MoveR::convert2Tracklets(TRexDat[-which(names(TRexDat) == "ntargets" | names(TRexDat) == "timestamps")], by = "identity")

```

Now we have imported the data, we can clean them to remove for instance:

  * infinite values corresponding to the moments where the particles were undetected 
  
  * probable spurious elements detected by the tracking software using several filters based on the particles size, speed, location within the arena). 
  
For this purpose, 3 main functions, `filterFunc()`, `mergeFilters()` and `filterTracklets()` allow to specify custom filters, merge several filters and use them to clean the data, respectively.

## Remove infinite values 

Infinite values are added by TRex when the particles are temporarily undetected, the following code help to remove infinite value and split the trajectories carrying them accordingly. 

In other words, when a particle is temporarily undetected we assume that the identity of the tracklet is spurious (conservative approach), thus the function create a new tracklet with a new identity (trackletId). Nevertheless, the original identity of the particles is still conserved in the "identity" vector.

Because infinite values can be detected in both x and y coordinates (i.e., x.pos and y.pos) we are using `filterFunc()` to create the filters on each variable and then `mergeFilter()` to combine the two filters.

```{r InfFilt}
# specify the filter to detected infinite values on "x.pos"
filter.InfX <-
  MoveR::filterFunc(
    trackDat,
    toFilter = "x.pos",
    customFunc = function(x)
      is.infinite(x)
  )

# it is also possible to group two or more filter by using the mergeFilter function
# for instance by merging the result of several condition tests, here the detection of infinite value in "x.pos" and "y.pos".

## first specify the second filter
filter.InfY <-
  MoveR::filterFunc(
    trackDat,
    toFilter = "y.pos",
    customFunc = function(x)
      is.infinite(x)
  )

## then merge the previously specifed filter
filter.Inf <-
  MoveR::mergeFilters(filters = list(filter.InfX, filter.InfY),
                     cond = TRUE)

```

Now, that the filter is properly specified the dataset can be filtered to remove infinite values detected on both x and y coordinates using `filterTracklets()`.

<p class="notes">Note that in case a particle is lost and detected again during a very short time period, the function may return small tracklets which may be considered useless. These small tracklets can be removed by specifying the minimum duration above which tracklet should be kept using the `minDur` argument.</p>

For this example, we are keeping only the tracklets lasting more than one second by setting minDur to 25 frames which correspond to 1 second, or to the frame rate of the video (hence we can use the frameRate object defined above).

```{r InfRemove, results='markup'}
# filter infinite values according to the previously specified filters
# here we are also removing the tracklets that are shorter than 25 frames (1 second) using the minDur argument.
trackDat.Infilt <-
  MoveR::filterTracklets(trackDat,
                     filter = filter.Inf,
                     splitCond = TRUE,
                     minDur = frameRate)

# display the summary of the filtering process
str(trackDat.Infilt[[1]])

```

The function output correspond to a list containing 2 sublists:

  * the first one being a summary of the filtering process
  
  * the second containing the list of filtered tracklets which can be used for further computation
  
See the help page of the function for more details (`filterTracklets()`)

According to the summary of the filtering process the number of tracklet drastically increases after the filtering (Tracknb_before_filter = 88 -> Tracknb_after_filter = 165583 tracklets). However a large amount appears to be very short which may be due to punctual detection of an individual over the timeline. 

This observation is confirmed because specifying the `minDur` argument removed an important part of these tracklets (Tracknb_after_filter = 165583 -> Tracknb_after_minDur = 6989 tracklets). 

Hence, there is a lot of moments where the micro-wasps were undetected within the dataset. As results, the filtering removed 64.7% (100-35.3) of the data corresponding to infinite values and then removed another 10.2% (35.3-25.1) because the resulting tracklets were shorter than 1 second (25 frames).

Now that we have removed the infinite values from the dataset, we can identify spurious detection by filtering on particles size.

## Filter based on particles size 

To remove the spurious detection of particles generated over the video-tracking procedure, one cleaning step can consist on removing all the moment when a particles' size is lower or higher than a given threshold (e.g., the known size of the animals).

We first retrieve the scaling of the video using the diameter of the circular arena measuring 2.5cm and it's length in pixels. 

Then, we know that <em>Trichogramma</em>'s body length is generally higher than 0.15mm and lower than 1mm (personal observation) we can hence use these limits to filter the particles for which the length is not included within this interval (fig. \@ref(fig:SizeClean)A&B). 

```{r SizeClean, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="100%", fig.cap="Histogram of the Log-transformed length of the particles and specified limits (vertical lines corresponding to 0.015 and 0.1 cm) of the distribution before (A) and after the filtering process (B) removing the moments where the particles' length is below or above the specified limits."}
# the scaling of the video - 1 cm represent 413.4 pixels (measured using the arena diameter -2.5cm- and ImageJ)
scaling <- 1 / 413.4

# the upper and lower limits to filter on particles length, according to the scale (expressed in cm)
LengthLim <- c(0.015, 0.1)

# convert the previously filtered data into a list to ease particle's size conversion (from pixels to cm)
trackDat.InfiltList <-  MoveR::convert2List(trackDat.Infilt[[2]])

# Use analyseTracklets function to scale the length of the particles (maj.ax) in cm by iterating over the tracklets
trackDat2 <- MoveR::analyseTracklets(trackDat.Infilt[[2]],
                                     customFunc =
                                       list(indLengthcm = function(x) x[["maj.ax"]] * scaling))

# plot the distribution of particles' length (log10) and the size limits
par(mfrow=c(1,2))
hist(log10(MoveR::convert2List(trackDat2)[["indLengthcm"]]),
     breaks = 50,
     main = paste0("Particles' length (log10) and \ntreshold (cm)= ", LengthLim[1], "; ", LengthLim[2]),
     xlab = "Particles' length (log10)",
     cex.main = 0.8)
abline(v = log10(LengthLim), col = "firebrick")
mtext(substitute(paste(bold("A"))), side = 3, line = 0, adj = 0, padj = -0.5)

# create the filter
filter.length <-
  MoveR::filterFunc(
    trackDat2,
    toFilter = "indLengthcm",
    customFunc = function(x)
      x < LengthLim[1] | x > LengthLim[2]
  )

# apply the filter on the data using the frame rate as minimum duration of the tracklets
trackDat.lenfilt <-
  MoveR::filterTracklets(trackDat2,
                     filter.length,
                     splitCond = TRUE,
                     minDur = frameRate)

# plot the distribution of particles' length (log10) after the filtering
hist(log10(MoveR::convert2List(trackDat.lenfilt[[2]])$maj.ax),
     breaks = 50,
     main = "Particles' length (log10) \nafter filtering",
     xlab = "Particles' length (log10)",
     cex.main = 0.8)
mtext(substitute(paste(bold("B"))), side = 3, line = 0, adj = 0, padj = -0.5)

```

```{r SizeCleanSTR, echo=TRUE, results='markup'}
# display the information about the filtering process (see ??filterTracklets())
str(trackDat.lenfilt[[1]])

```

According to the summary of the filtering step based on particles' size, the amount of data removed by the filtering is reasonable with 3.7% of data considered above or below the particles' length threshold.

However, the filter splited some tracklets in small part resulting in an additional 2.5% of data removed because resulting tracklets were shorter than 1 second (25 frames).

While the size of the particles is a good way to remove potential spurious detection, another efficient way to filter the data is based on the particles' speed.

## Filter based on particles speed 

Indeed, the particles' speed can be a good indicator of spurious detection or particle identification. More particularly, When the speed of a particle is too high (and have hence no biological meaning) it can be due to change in particle identity or more generally tracking artifact. 

However, While the data can be filtered based data that already exist into the raw output of the tracking software, here the speed of the particles is not included, and in any case it should be recomputed since we have modified the tracklets over the previous filtering processes.

For the sacks of this example we will use the 999<sup>th</sup> percentile as a treshold above which particles' speed are considered artifactual.

```{r SpeedClean, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="100%", fig.cap="Histogram of the Log-transformed speed of the particles and 999th quantile (vertical line) of the distribution before (A) and after the filtering process (B) removing the moments where the particles' speed is above the 999th quantile."}
# retrieve the previously filtered data and used them to compute particles' speed
trackDat3 <- trackDat.lenfilt[[2]]

# Use analyseTracklets function to compute the speed of the particles by iterating over the tracklets
# here we use the "speed()" modulus to compute the speed over each tracklet
trackDat3 <-
  MoveR::analyseTracklets(trackDat3,
                      customFunc = list(
                        speed = function(x)
                          MoveR::speed(
                            x,
                            timeCol = "runTimelinef",
                            scale = 1
                          )
                      ))

# retrieve the speed of all particles in a vector
particleSpeed <- MoveR::convert2List(trackDat3)[["speed"]]

# compute the 999th percentile of particles' speed (log10 transformed data)
quant999th <- quantile(log10(particleSpeed), c(0.999), na.rm = T)

# plot the particles' speed (log10) distribution and the 999th percentile before filtering
par(mfrow=c(1,2))
hist(log10(particleSpeed), breaks = 100, main = "particles' speed (log10) and 999th quantile \nbefore filtering",
     cex.main= 0.9,
     xlab = "Particles' speed (log10)")
abline(v = quant999th, col = "#660000")
mtext(substitute(paste(bold("A"))), side = 3, line = 0, adj = 0, padj = -0.5)

# the result seem satisfactory since with this threshold we will remove only the few moments where particles speed overpass 22.5 pixels per frame while we conserve the bimodal distribution of the particles' speed.
# hence, create the filter based on the computed 999th quantile 
filter.speed <-
  MoveR::filterFunc(
    trackDat3,
    toFilter = "speed",
    customFunc = function(x)
      x < 0 | x > 10 ^ quant999th
  )

# apply the filter on the data using the frame rate as minimum duration of the tracklets
trackDat.speedfilt <-
  MoveR::filterTracklets(trackDat3,
                     filter.speed,
                     splitCond = TRUE,
                     minDur = frameRate)

# plot particles' speed (log10) distribution after the filtering
hist(log10(MoveR::convert2List(trackDat.speedfilt[[2]])[["speed"]]),
     breaks = 100,
     main = "Particles' speed (log10) \nafter filtering",
     cex.main= 0.9,
     xlab = "Particles' speed (log10)")
mtext(substitute(paste(bold("B"))), side = 3, line = 0, adj = 0, padj = -0.5)

```

```{r SpeedCleanSTR, echo=TRUE, results='markup'}
# display the information about the filtering process (see ??filterTracklets())
str(trackDat.speedfilt[[1]])

```

According to the summary of the filtering step based on particles' speed, the amount of data removed by the filtering is reasonable with 0.1% of data considered above the speed threshold, which is consistent with our approach since we wanted to remove only extremes values (999Th quantile, fig. \@ref(fig:SpeedClean)A&B). 

Also, the filter splited only few tracklets in small part resulting in an additional 0.8% of data removed because resulting tracklets were shorter than 1 second (25 frames).

Finally, it seems interesting to remove the particles that are detected outside of the arena since it should be due to tracking artifact, or more generally to unintended particles' detection and movements.

## Filter based on particles detection outside the arena

Indeed, sometimes particles can be detected outside the arena, either because an individual as escaped from the arena or because the background has changed over the video recording (tracking artifact). 

To solve this issue, it is possible to remove the parts of a tracklet that have been detected outside the arena. 

To tackle this aim, one may either use the already implemented functions to generate the edge of circular or polygonal ROIs (see `circles()` and `polygons()`) or retrieving the position of the arena (or any ROI) edge from a distance matrix generated trough an image processing program such as <a href="https://imagej.net/ij/index.html">ImageJ</a>.

We first need to retrieve or generate the points specifying the arena edge: 
```{r edgeDef, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="100%", fig.cap="Representation of centre and edge of the arena retrieved from a distance matrix generated using color tresholding in imageJ. The position of the arena edge can be extracted from the distance matrix as the lowest value of distance matrix (i.e., 1) and the centre of the arena as the mean of the edge x and y coordinates."}

# retrieve the location of the arena edge from a distance matrix generated using color tresholding in imageJ
# as color tresholding returns a matrix with image resolution (x in rows and y in columns) and increasing distance to the edge of the arena, here the edge correspond 
# to the lower value of the distance matrix (i.e., 1).
# Also specifying the order argument as TRUE ensure that the points delimiting the arena edge are sorted clockwise, making easy to draw the edge.
edge <- MoveR::locROI(Path2Data[[2]], edgeCrit = 1, xy = 1, order = T)
# here the coordinates of the arena edge are stored in the edge object

# it is then easy to draw the arena edge
plot(NULL, 
     xlim = c(0, max(edge[, "x.pos"])), 
     ylim = c(0, max(edge[, "y.pos"])),
     xlab = "Video width (pixels)",
     ylab = "Video height (pixels)",
     main = "Edge and centre of the arena",
     cex.main = 0.9)
graphics::polygon(x = edge[["x.pos"]], edge[["y.pos"]], lty = 2, col = adjustcolor("firebrick", alpha = 0.2))

# As well as the center of the arena
graphics::points(
  x = mean(edge[["x.pos"]]),
  y = mean(edge[["y.pos"]]),
  col = "black",
  pch = 3,
  cex = 1
)

# Note that, in the case of a circular arena, by knowing the coordinates of the center of the arena and the length of the diameter (2.5cm) allows to generate the coordinates of the border of the arena using the circles() function from the MoveR package. Similar method can also be used for polygonal shape using the polygons() function from the MoveR package.
ArenaEdge <- MoveR::circles(
  mean(edge[["x.pos"]]),
  mean(edge[["y.pos"]]),
  radius = 2.5 / 2 / scaling, # here the radius of the arena is 2.5cm/2 divided by the scaling to obtain the value in pixels
  border = "firebrick",
  draw = T
)
# here the coordinates of the arena edge are then stored in the ArenaEdge object
```

Here the distance matrix generated using <a href="https://imagej.net/ij/index.html">ImageJ</a> returns decreasing distance from the centre of the arena to the edge.

Accordingly, the lowest value (i.e., 1) corresponds to the edge of the arena (fig. \@ref(fig:edgeDef), black line). Hence, the use of a distance matrix may be a a good option to retrieve the location of the edge of an arena or any ROI, whatever its shape.

However, in the case of using a classic circular or polygonal arena a simpler approach would consist of generating the expected arena edge using `circles()` or `polygons()` and feeding the former with coordinates of the arena center and the radius length (fig. \@ref(fig:edgeDef), red line).

We can then easily identify whether a particle is detect within or outside the arena by assigning the ROI to each tracklet using the `assignROI()` and filtering out the tracklets parts detected outside the arena. 

```{r edgeClean, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="100%", fig.cap="Micro-wasps trajectories over the whole video timeline, expressed in frame. The arena edges are represented by the black circle."}
## assign The ROI (here the arena) to the particles' positions
trackDat4 <-
  MoveR::analyseTracklets(trackDat.speedfilt[[2]],
                          customFunc = list(
                            Arena = function(x)
                              MoveR::assignROI(
                                x,
                                ROIs = edge,
                                edgeInclude = F,
                                order = T
                              )
                          ))

# draw the tracklet and the arena edges 
MoveR::drawTracklets(trackDat4,
                     timeCol = "runTimelinef",
                     add2It = list(graphics::polygon(x = edge$x.pos, y = edge$y.pos)))

```

Apparently the amount of artifact detected outside the arena is null or very low (see fig. \@ref(fig:edgeClean). However, by using `assignROI()` and excluding the edge some tracklet part are indeed detected outside the arena.

```{r FiltOut, echo=TRUE, results='markup'}
# create the filter to remove particles outside the arena
filter.out <-
  MoveR::filterFunc(
    trackDat4,
    toFilter = "Arena",
    customFunc = function(x)
      x == FALSE
  )

# apply the filter on the data using the frame rate as minimum duration of the tracklets
trackDat.borderfilt <-
  MoveR::filterTracklets(trackDat4,
              filter.out,
              splitCond = TRUE,
              minDur = frameRate)

# rename the cleaned dataset for further use
trackDat5 <- trackDat.borderfilt[[2]]

# check that the particle detected outside has been removed
## retrieve the ROI assignation before and after filtering
compar <- list(
  before = MoveR::convert2List(trackDat4)[["Arena"]],
  after = MoveR::convert2List(trackDat5)[["Arena"]]
)

## create a count table to determine the amount of tracklets parts that are within and outside the arena
res <- data.frame(matrix(NA, nrow = 2, ncol = 2))
colnames(res) <- unique(compar[[1]])
rownames(res) <- unique(names(compar))
for (i in seq_along(compar)) {
  res[i, "ROI_1"] <- length(grep("\\<ROI_1\\>", compar[[i]]))
  res[i, "FALSE"] <- length(grep("\\<FALSE\\>", compar[[i]]))
}

res
```

Then, as expected the filtering step based the location of the particles inside or outside the arena have removed parts of the tracklets (54 occurrences) detected outside the arena (ROI_1). 

```{r edgeCleanSTR, echo=TRUE, results='markup'}
# display the information about the filtering process (see ??filterTracklets())
str(trackDat.borderfilt[[1]])

```
 
In addition, according to the summary of the filtering step, the amount of data removed by the filtering is very low (<0.1%), confirming that there is few tracking artifact outside of the arena (fig. \@ref(fig:edgeClean)). 

Accordingly, the filter splited only few tracklets in small part resulting in less than 0.1% of data removed because resulting tracklets were shorter than 1 second (25 frames).

While the count table and the summary of the filtering give a general quantitative view of the amount of data removed by the filtering step one may also want to have an idea of the tracklets identity and the spatio-temporal distribution of the removed data. For this we can use `drawTracklets()` as follow:

```{r edgeCleanBeforeAfterOut, echo=TRUE, results='markup'}
# identify the part of the tracklets that are detected outside the arena
trackDat4List <- MoveR::convert2List(trackDat4)
OutTracklets <- unique(trackDat4List[["trackletId"]][which(trackDat4List[["Arena"]] == FALSE)])
OutTracklets
```


```{r edgeCleanBeforeAfter, results='asis', message=FALSE, warning=FALSE, fig.align = 'center', out.width="100%", fig.cap="Representation of the particles' trajectories detected outside the arena before the filtering process removing the moments where the particles are detected outside of the arena."}
# identify the part of the tracklets that are detected outside the arena
trackDat4List <- MoveR::convert2List(trackDat4)
OutTracklets <- unique(trackDat4List[["trackletId"]][which(trackDat4List[["Arena"]] == FALSE)])
OutTracklets

# plot them
MoveR::drawTracklets(
  trackDat4,
  selTrack = OutTracklets,
  main = ,
  cex.main = 0.9,
  cex.start = 1, # increase the size of the start points of the tracklet (help to locate it, particularly if the particle is still)
  add2It = list(graphics::polygon(x = edge$x.pos, y = edge$y.pos))
)

```

Here we can see that the tracklets' part detected outside the arena belong to two tracklets that stayed still over the video-recording ("Tracklet_2" and "Tracklet_3724"). We can thus be confident about the fact that it should be considered as tracking artifacts.

Now we have achieved the filtering of the dataset, one would take a look and eventually save a summary of the filtering procedure.


## Filtering/Cleaning summary

Once the filtering/cleaning steps are done, the various filter summaries can be retrieved and easily grouped and eventually saved.

```{r CleaningSummary}
# create a summary of each filter results 
FilterSummary <- do.call("cbind",
                         list(
                           data.frame(Infilt = unlist(trackDat.Infilt[[1]])),
                           data.frame(lenfilt = unlist(trackDat.lenfilt[[1]])),
                           data.frame(speedfilt = unlist(trackDat.speedfilt[[1]])),
                           data.frame(outfilt = unlist(trackDat.borderfilt[[1]]))
                         ))

# add cumulative_%Data_kept_after_filter and after_minDur
FilterSummary <- rbind(FilterSummary, 
      apply(FilterSummary, 2, FUN = function(x) as.numeric(x[5])/FilterSummary[4,1]*100),
      apply(FilterSummary, 2, FUN = function(x) as.numeric(x[6])/FilterSummary[4,1]*100))
rownames(FilterSummary)[c(9,10)] <- c("cumulative_%Data_kept_after_filter", 
                                      "cumulative_%Data_kept_after_minDur")

FilterSummary

```

As previously stated, we can indeed see that the filter based on infinite values have removed a lot of data contrary to the other filters. Also, it seems that the minimum duration of the tracklets set to 25 frames (1 second) is appropriate since it remove a small amount of data.

It is also possible to display a summary of the tracking information of both the initial dataset (i.e., trackDat) and the filtered/cleaned one (trackDat5) using `trackStats()` to quickly compare them.

```{r TrackStatsSummary, message=FALSE, warning=FALSE}
# compute and display a detailed summary of the tracking information before and after cleaning (see ??trackStats())
Data_Trex_stats_before_filter <-
  MoveR::trackStats(trackDat,
                    frameR = frameRate,
                    scale = scaling,
                    unit = "cm")

Data_Trex_stats_after_filter <-
  MoveR::trackStats(trackDat5,
                    frameR = frameRate,
                    scale = scaling,
                    unit = "cm")

```

By comparing the summary of the tracking information before and after the filtering process, we can see that video characteristics are unchanged. 

On the contrary, tracklets are more numerous and shorter after the filtering than before which is not surprising since we have removed biased data and splited the tracklets accordingly.  

Both kind of summaries can then be saved as a .csv file using common function such as `utils::write.csv()` or `data.table::fwrite()`. 

Also, the filtered dataset can be saved before using it for further computations. 
As such dataset can be large we recommend to use `data.table::fwrite()` from the data.table package as well as saving the data as .gz archive to save as much disk space as possible (e.g., For this dataset: .csv = 181Mo vs .csv.gz = 62Mo).

```{r SaveTheData, eval=FALSE}
# save the cleaned dataset as .csv compressed as .gz
data.table::fwrite(
  MoveR::convert2List(trackDat5),
  paste(paste(dirname(Path2Data[1]), "cleanedData", sep = "/"
  ), "csv", "gz", sep = "."),
  sep = ";",
  dec = ".",
  na = "NA",
)

```

Now that the filtering/cleaning process is achieved, we can move to data analysis through various metrics computations.

<p class="notes">Note, however, that ones would add or replace some of the filters that have been used in this example depending on the model species and the study' aims. 

Accordingly, the various function developed in the MoveR package are very flexible and allow the user to specify custom functions to break limits.</p>

For more insight how to use MoveR to run further computation check the next tutorials. 

<strong>Happy coding.</strong>


<a href="https://qpetitjean.github.io/MoveR/articles/MoveR-ImportData.html" class="previous">&laquo; Previous</a><a href="https://qpetitjean.github.io/MoveR/articles/MoveR-ComputeMetrics.html" class="next">Next &raquo;</a><br />


## References

  * Ion Scotta, M., Margris, L., Sellier, N., Warot, S., Gatti, F., Siccardi, F., Gibert, P., Vercken, E., Ris, N., 2021. Genetic Variability, Population Differentiation, and Correlations for Thermal Tolerance Indices in the Minute Wasp, Trichogramma cacoeciae. Insects 12, 1013. https://doi.org/10.3390/insects12111013

  * Walter, T., Couzin, I.D., 2021. TRex, a fast multi-animal tracking system with markerless identification, and 2D estimation of posture and visual fields. eLife 10, e64000. https://doi.org/10.7554/eLife.64000